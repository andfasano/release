kind: Template
apiVersion: template.openshift.io/v1

parameters:
- name: JOB_NAME_SAFE
  required: true
- name: JOB_NAME_HASH
  required: true
- name: NAMESPACE
  required: true
- name: IMAGE_FORMAT
- name: IMAGE_INSTALLER
  required: true
- name: IMAGE_LIBVIRT_INSTALLER
  required: true
- name: IMAGE_TESTS
  required: true
- name: IMAGE_UPI_INSTALLER
  required: true
- name: CLUSTER_TYPE
  required: true
- name: TEST_COMMAND
  required: true
- name: RELEASE_IMAGE_LATEST
  required: true
- name: BASE_DOMAIN
- name: CLUSTER_NETWORK_MANIFEST
- name: CLUSTER_NETWORK_TYPE
- name: BUILD_ID
  required: false
- name: CLUSTER_VARIANT

objects:

# We want the cluster to be able to access these images
- kind: RoleBinding
  apiVersion: authorization.openshift.io/v1
  metadata:
    name: ${JOB_NAME_SAFE}-image-puller
    namespace: ${NAMESPACE}
  roleRef:
    name: system:image-puller
  subjects:
  - kind: SystemGroup
    name: system:unauthenticated
  - kind: SystemGroup
    name: system:authenticated

# Give admin access to a known bot
- kind: RoleBinding
  apiVersion: authorization.openshift.io/v1
  metadata:
    name: ${JOB_NAME_SAFE}-namespace-admins
    namespace: ${NAMESPACE}
  roleRef:
    name: admin
  subjects:
  - kind: ServiceAccount
    namespace: ci
    name: ci-chat-bot

# Role for giving the e2e pod permissions to update imagestreams
- kind: Role
  apiVersion: authorization.openshift.io/v1
  metadata:
    name: ${JOB_NAME_SAFE}-imagestream-updater
    namespace: ${NAMESPACE}
  rules:
  - apiGroups: ["image.openshift.io"]
    resources: ["imagestreams/layers"]
    verbs: ["get", "update"]
  - apiGroups: ["image.openshift.io"]
    resources: ["imagestreams", "imagestreamtags"]
    verbs: ["get", "create", "update", "delete", "list"]

# Give the e2e pod access to the imagestream-updater role
- kind: RoleBinding
  apiVersion: authorization.openshift.io/v1
  metadata:
    name: ${JOB_NAME_SAFE}-imagestream-updater-binding
    namespace: ${NAMESPACE}
  roleRef:
    kind: Role
    namespace: ${NAMESPACE}
    name: ${JOB_NAME_SAFE}-imagestream-updater
  subjects:
  - kind: ServiceAccount
    namespace: ${NAMESPACE}
    name: default

# The e2e pod spins up a cluster, runs e2e tests, and then cleans up the cluster.
- kind: Pod
  apiVersion: v1
  metadata:
    name: ${JOB_NAME_SAFE}
    namespace: ${NAMESPACE}
    annotations:
      # we want to gather the teardown logs no matter what
      ci-operator.openshift.io/wait-for-container-artifacts: teardown
      ci-operator.openshift.io/save-container-logs: "true"
      ci-operator.openshift.io/container-sub-tests: "setup,test,teardown"
  spec:
    restartPolicy: Never
    activeDeadlineSeconds: 18000
    terminationGracePeriodSeconds: 900
    volumes:
    - name: artifacts
      emptyDir: {}
    - name: shared-tmp
      emptyDir: {}
    - name: cluster-profile
      secret:
        secretName: ${JOB_NAME_SAFE}-cluster-profile

    containers:
    # Once the cluster is up, executes shared tests
    - name: test
      image: ${IMAGE_TESTS}
      terminationMessagePolicy: FallbackToLogsOnError
      resources:
        requests:
          cpu: 3
          memory: 600Mi
        limits:
          memory: 4Gi
      volumeMounts:
      - name: shared-tmp
        mountPath: /tmp/shared
      - name: cluster-profile
        mountPath: /tmp/cluster
      - name: artifacts
        mountPath: /tmp/artifacts
      env:
      - name: ARTIFACT_DIR
        value: /tmp/artifacts
      - name: HOME
        value: /tmp/home
      - name: KUBECONFIG
        value: /tmp/artifacts/installer/auth/kubeconfig
      command:
      - /bin/bash
      - -c
      - |
        #!/bin/bash
        set -exuo pipefail

        export PATH=/usr/libexec/origin:$PATH

        trap 'touch /tmp/shared/exit' EXIT
        trap 'jobs -p | xargs -r kill || true; exit 0' TERM

        mkdir -p "${HOME}"

        # Share oc with other containers
        cp "$(command -v oc)" /tmp/shared

        # wait for the API to come up
        while true; do
          if [[ -f /tmp/shared/setup-failed ]]; then
            echo "Setup reported a failure, do not report test failure" 2>&1
            exit 0
          fi
          if [[ -f /tmp/shared/exit ]]; then
            echo "Another process exited" 2>&1
            exit 1
          fi
          if [[ ! -f /tmp/shared/setup-success ]]; then
            sleep 15 & wait
            continue
          fi
          # don't let clients impact the global kubeconfig
          cp "${KUBECONFIG}" /tmp/admin.kubeconfig
          export KUBECONFIG=/tmp/admin.kubeconfig
          break
        done

        # if the cluster profile included an insights secret, install it to the cluster to
        # report support data from the support-operator
        if [[ -f /tmp/cluster/insights-live.yaml ]]; then
          oc create -f /tmp/cluster/insights-live.yaml || true
        fi

        # set up cloud-provider-specific env vars
        if [ "${CLUSTER_TYPE}" == "metal" ] ; then
          export HOME=/tmp/shared/nss_wrapper
          export NSS_WRAPPER_PASSWD=$HOME/passwd NSS_WRAPPER_GROUP=$HOME/group NSS_USERNAME=nsswrapper NSS_GROUPNAME=nsswrapper LD_PRELOAD=/tmp/shared/libnss_wrapper.so
          export IP=$(cat /tmp/shared/packet-server-ip)
          SSHOPTS="-o ConnectTimeout=5 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o ServerAliveInterval=90 -i /tmp/cluster/ssh-privatekey"
          scp $SSHOPTS /usr/bin/openshift-tests /usr/bin/kubectl root@$IP:/usr/local/bin
          oc config  set-cluster ostest --server=https://api.ostest.test.metalkube.org:6443 --insecure-skip-tls-verify
        else
          echo "Unsupported cluster type"
          exit 1
        fi

        mkdir -p /tmp/output
        cd /tmp/output

        function run-remote-tests() {
          set +e
          ssh $SSHOPTS root@$IP openshift-tests run "${TEST_SUITE}" --dry-run \| grep -Fvf dev-scripts/filtered-tests \| openshift-tests run -o /tmp/artifacts/e2e.log --junit-dir /tmp/artifacts/junit -f -
          rv=$?
          ssh $SSHOPTS root@$IP tar -czf - /tmp/artifacts | tar -C / -xzf - 
          set -e
          return $rv
        }

        function run-remote-smoke-tests() {
          set +e
          ssh $SSHOPTS root@$IP openshift-tests run "${TEST_SUITE}" --dry-run \| grep -Fvf dev-scripts/filtered-tests \| grep 'Smoke' \| openshift-tests run -o /tmp/artifacts/e2e.log --junit-dir /tmp/artifacts/junit -f -
          rv=$?
          ssh $SSHOPTS root@$IP tar -czf - /tmp/artifacts | tar -C / -xzf - 
          set -e
          return $rv
        }

        ${TEST_COMMAND}
    
    # The setup-packet and test containers need libnns_wrapper to use ssh
    # TODO(derekh): investigate if it can be added to that container images
    - name: nss-wrapper-hack
      image: ${IMAGE_LIBVIRT_INSTALLER}
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - name: shared-tmp
        mountPath: /tmp/shared
      command:
      - /bin/bash
      - -c
      - |
        #!/bin/bash
        set -exuo pipefail
        cp /bin/mock-nss.sh /usr/lib64/libnss_wrapper.so /tmp/shared/

    # We need to have a seperate setup container for packet.net servers
    # as we need an image with terrafrom
    # TODO(andrea): Define ad hoc container for terraform
    # TODO(andrea): Project id is currently hard-coded
    # TODO(andrea): MIRROR_BASE is not currently honoring dev-scripts OPENSHIFT_RELEASE_IMAGE
    - name: setup
      image: ${IMAGE_UPI_INSTALLER}
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - name: shared-tmp
        mountPath: /tmp/shared
      - name: cluster-profile
        mountPath: /tmp/cluster
      - name: artifacts
        mountPath: /tmp/artifacts
      env:
      - name: CLUSTER_NAME
        value: ${NAMESPACE}-${JOB_NAME_HASH}
      - name: PACKET_PROJECT_ID
        value: f68bd149-488a-4b58-90a2-d675cfb78728
      - name: PULL_SECRET_PATH
        value: /tmp/cluster/pull-secret
      - name: MIRROR_BASE
        value: registry.svc.ci.openshift.org/${NAMESPACE}/release
      command:
      - /bin/sh
      - -c
      - |
        #!/bin/sh
        set -exuo pipefail

        if [ "${CLUSTER_TYPE}" != "metal" ] ; then
            exit 0
        fi

        finished()
        {
            set +e

            if [ -n "$IP" ] ; then
                echo "Getting logs"
                ssh $SSHOPTS root@$IP tar -czf - /root/dev-scripts/logs | tar -C /tmp/artifacts -xzf -
                sed -i -e 's/.*auths.*/*** PULL_SECRET ***/g' /tmp/artifacts/root/dev-scripts/logs/*
            fi

            echo "Deprovisioning cluster ..."
            cd /tmp/artifacts/terraform
            terraform init
            for r in {1..5}; do terraform destroy -auto-approve && break ; done
            touch /tmp/shared/exit
        }
        trap finished EXIT TERM

        mkdir -p /tmp/artifacts/terraform
        cd /tmp/artifacts/terraform

        set +x
        export PACKET_AUTH_TOKEN=$(cat /tmp/cluster/.packetcred)
        set -x

        cat > /tmp/artifacts/terraform/terraform.tf <<-EOF
        provider "packet" {
        }

        resource "packet_device" "server" {
          count            = "1"
          project_id       = "$PACKET_PROJECT_ID"
          hostname         = "ipi-$CLUSTER_NAME"
          plan             = "m2.xlarge.x86"
          facilities       = ["sjc1", "ewr1"]
          operating_system = "centos_7"
          billing_cycle    = "hourly"
        }

        EOF

        terraform init
        # Packet returns transients errors when creating devices.
        # example, `Oh snap, something went wrong! We've logged the error and will take a look - please reach out to us if you continue having trouble.`
        # therefore the terraform apply needs to be retried a few time before giving up.
        rc=1
        for r in {1..5}; do terraform apply -auto-approve && rc=0 && break ; done
        if test "${rc}" -eq 1; then echo "failed to create the infra resources"; sleep 1; fi

        jq -r '.modules[0].resources["packet_device.server"].primary.attributes.access_public_ipv4' terraform.tfstate > /tmp/shared/packet-server-ip

        export HOME=/tmp/shared/nss_wrapper
        export NSS_WRAPPER_PASSWD=$HOME/passwd NSS_WRAPPER_GROUP=$HOME/group NSS_USERNAME=nsswrapper NSS_GROUPNAME=nsswrapper LD_PRELOAD=/tmp/shared/libnss_wrapper.so
        mkdir -p $HOME
        bash /tmp/shared/mock-nss.sh

        SSHOPTS="-o ConnectTimeout=5 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o ServerAliveInterval=90 -i /tmp/cluster/ssh-privatekey"
        export IP=$(cat /tmp/shared/packet-server-ip)

        for x in $(seq 10) ; do
            test $x == 10 && exit 1
            ssh $SSHOPTS root@$IP hostname && break
            sleep 10
        done

        scp $SSHOPTS ${PULL_SECRET_PATH} root@$IP:pull-secret
        timeout -s 9 175m ssh $SSHOPTS root@$IP bash - << EOF |& sed -e 's/.*auths.*/*** PULL_SECRET ***/g'
        set -ex

        yum install -y git

        # python2-cryptography needs to come from delorean-master-testing, priority of packet.repo overrides it
        # remove the priority and instead ensure the packet repo is named first alphabetically
        # this way it is prefered but it isn't a hard override when newer versions are found elsewhere
        sed -i -e 's/priority.*//g' /etc/yum.repos.d/packet.repo
        sed -i -e 's/packet-/a_packet-/g' /etc/yum.repos.d/packet.repo

        rm -rf /tmp/artifacts
        mkdir -p /tmp/artifacts

        if [ ! -e dev-scripts ] ; then
            git clone https://github.com/openshift-metal3/dev-scripts.git
        fi
        cd dev-scripts

        set +x
        echo "export PULL_SECRET='\$(cat /root/pull-secret)'" > /root/dev-scripts/config_root.sh
        set -x

        curl https://mirror.openshift.com/pub/openshift-v4/clients/oc/4.4/linux/oc.tar.gz | tar -C /usr/bin -xzf -

        echo "export OPENSHIFT_RELEASE_IMAGE=$MIRROR_BASE:latest" >> /root/dev-scripts/config_root.sh
        #echo "export OPENSHIFT_RELEASE_IMAGE=registry.svc.ci.openshift.org/ocp/release:4.4.0-0.nightly-2020-01-29-012724" >> /root/dev-scripts/config_root.sh
        echo "export ADDN_DNS=\$(awk '/nameserver/ { print \$2;exit; }' /etc/resolv.conf)" >> /root/dev-scripts/config_root.sh
        echo "export OPENSHIFT_CI=true" >> /root/dev-scripts/config_root.sh
        echo "export MIRROR_IMAGES=true" >> /root/dev-scripts/config_root.sh

        echo 'export KUBECONFIG=/root/dev-scripts/ocp/auth/kubeconfig' >> /root/.bashrc

        if [ ! -e /opt/dev-scripts/pool ] ; then
            mkdir -p /opt/dev-scripts/pool
            mount -t tmpfs -o size=100G tmpfs /opt/dev-scripts/pool
        fi

        timeout -s 9 105m make

        EOF

        mkdir -p /tmp/artifacts/installer/auth
        scp $SSHOPTS root@$IP:./dev-scripts/ocp/auth/kubeconfig /tmp/artifacts/installer/auth/kubeconfig

        touch /tmp/shared/setup-success
        while [ ! -f /tmp/shared/exit ] ; do sleep 1 ; done

